vocab:
  type: RichVocab
  max_sents: 50
  max_sent_len: 100
  path:
    train: datasets/Wikilingual-dataset/train.json
    dev: datasets/Wikilingual-dataset/dev.json
    test: datasets/Wikilingual-dataset/test.json
  min_freq: 3
  bos_token: <bos>
  eos_token: <eos>
  unk_token: <unk>
  pad_token: <pad>
  spacy_model: vi_core_news_lg
  pos_tags: []
  ner_tags: []
  tfidf:
    smooth_idf: true
    sublinear_tf: true

dataset:
  train:
    type: HierarchicalTextSumDataset
    path: datasets/Wikilingual-dataset/train.json
    max_sents: 50
    max_sent_len: 100
  dev:
    type: HierarchicalTextSumDataset
    path: datasets/Wikilingual-dataset/dev.json
    max_sents: 50
    max_sent_len: 100
  test:
    type: HierarchicalTextSumDataset
    path: datasets/Wikilingual-dataset/test.json
    max_sents: 50
    max_sent_len: 100
  batch_size: 32
  num_workers: 16

model:
  layer_dim: 3
  name: AbstractiveTXModel_3layer_Wikilingual
  architecture: AbstractiveTXModel
  hidden_size: 512
  device: cuda
  dropout: 0.5
  teacher_forcing_ratio: 0.5
  coverage_loss_weight: 0.1
  encoder:
    word_emb_dim: 256
    pos_emb_dim: 64
    ner_emb_dim: 64
    tfidf_emb_dim: 32
    enc_hid_dim: 512
    bidirectional: true
  decoder:
    dec_emb_dim: 256
    dec_hid_dim: 512
    attention_dim: 256
    bidirectional: false

training:
  checkpoint_path: checkpoints
  learning_rate: 0.005
  warmup: 1000
  patience: 5
  score: rouge-L

task: TextSumTask

vocab:
  type: Vocab
  path:
    train: datasets/VietNews-dataset/train.json
    dev: datasets/VietNews-dataset/dev.json
    test: datasets/VietNews-dataset/test.json
  min_freq: 3
  bos_token: <bos>
  eos_token: <eos>
  unk_token: <unk>
  pad_token: <pad>

dataset:
  train: 
    type: TextSumDataset
    path: datasets/VietNews-dataset/train.json
  dev:
    type: TextSumDataset
    path: datasets/VietNews-dataset/dev.json
  test: 
    type: TextSumDataset
    path: datasets/VietNews-dataset/test.json
  batch_size: 32
  num_workers: 8

model:
  name: HEPOS_VietNews      # Tên checkpoint để dễ nhận biết
  architecture: HEPOSBaselineSummarizer # Tên lớp wrapper đã đăng ký với META_ARCHITECTURE
  EncoderConfig:
    d_model: 512
    n_layers: 6
    n_head: 8
    ffn_hidden: 2048
    drop_prob: 0.1
    max_len: 5000
    attn_type: sinkhorn  # 'full', 'sliding_window', 'lsh', 'sinkhorn'

  DecoderConfig:
    d_model: 512
    n_layers: 6
    n_head: 8
    ffn_hidden: 2048
    drop_prob: 0.1
    max_len: 1024
    stride: None # None = use n_head
  device: cuda
training:
  checkpoint_path: "checkpoints"
  warmup: 1000
  patience: 5
  score: rouge-L
  batch_size: 32
  learning_rate: 0.0001
  epochs: 20

task: TextSumTask
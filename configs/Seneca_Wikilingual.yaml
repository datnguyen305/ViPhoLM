vocab:
  type: Vocab
  path:
    train: datasets/Wikilingual-dataset/train.json
    dev: datasets/Wikilingual-dataset/dev.json
    test: datasets/Wikilingual-dataset/test.json
  min_freq: 3
  bos_token: <bos>
  eos_token: <eos>
  unk_token: <unk>
  pad_token: <pad>
  extra_tokens:
    - <MENT>

dataset:
  train:
    type: TextSumDatasetSeneca
    path: datasets/Wikilingual-dataset/train.json
    max_sent: 30
    max_sent_len: 50
  dev:
    type: TextSumDatasetSeneca
    path: datasets/Wikilingual-dataset/dev.json
    max_sent: 30
    max_sent_len: 50
  test:
    type: TextSumDatasetSeneca
    path: datasets/Wikilingual-dataset/test.json
    max_sent: 30
    max_sent_len: 50

  batch_size: 32
  num_workers: 8

model:
  name: seneca_baseline_wikilingual
  architecture: SENECA_Baseline
  d_model: 128
  hidden_dim: 256
  dropout: 0.1
  use_selector: true
  use_copy: true
  use_coverage: false
  max_extract: 5
  max_tgt_len: 128
  device: cuda

training:
  optimizer: adam
  learning_rate: 0.0005
  betas: [0.9, 0.999]
  scheduler: none
  epochs: 20
  warmup: 0
  patience: 5
  grad_clip: 2.0
  coverage_lambda: 0.0
  checkpoint_path: checkpoints
  score: rouge-L

task: TextSumTaskSeneca

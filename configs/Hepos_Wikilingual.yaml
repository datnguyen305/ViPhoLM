
vocab:
  type: Vocab
  path:
    train: datasets/Wikilingual-dataset/train.json
    dev: datasets/Wikilingual-dataset/dev.json
    test: datasets/Wikilingual-dataset/test.json
  min_freq: 3
  bos_token: <bos>
  eos_token: <eos>
  unk_token: <unk>
  pad_token: <pad>

dataset:
  train: 
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/train.json
  dev:
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/dev.json
  test: 
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/test.json
  batch_size: 32
  num_workers: 8
  max_src_len: 2048
  max_tgt_len: 512


model:
  name: HeposModel_Wililingual    
  architecture: HeposModel 
  d_model: 768
  encoder:
    num_layers: 4
    num_heads: 8
    block_size: 128

  decoder:
    num_layers: 4
    num_heads: 8
    hepos_stride: 16
  device: cuda

training:
  checkpoint_path: checkpoints
  score: rouge-L
  learning_rate: 0.0001
  warmup: 10000
  patience: 5
  max_epochs: 50
  grad_clip: 0.1


task: TextSumTask
vocab:
  type: Vocab
  path:
    train: datasets/Wikilingual-dataset/train.json
    dev: datasets/Wikilingual-dataset/dev.json
    test: datasets/Wikilingual-dataset/test.json
  min_freq: 3
  bos_token: <bos>
  eos_token: <eos>
  unk_token: <unk>
  pad_token: <pad>

dataset:
  train: 
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/train.json
  dev:
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/dev.json
  test:
    type: TextSumDataset
    path: datasets/Wikilingual-dataset/test.json
  batch_size: 32
  num_workers: 16

model:
  name: BiGRU_Model3layer_Wikilingual
  architecture: BiGRU_Model
  d_model: 512
  encoder:
    hidden_size: 256          # GRU hidden dimension
    layer_dim: 2              # number of GRU layers
    bidirectional: true       # BiGRU
    dropout: 0.2

  decoder:
    hidden_size: 256          # must match encoder hidden_size
    layer_dim: 2
    dropout: 0.2
  device: cuda

inference:
  beam_size: 1     

training:
  learning_rate: 0.15
  weight_decay: 0.00001
  optimizer: adam
  scheduler: none
  gradient_clip: 1.0
  label_smoothing: 0.1
  checkpoint_path: "checkpoints"
  warmup: 1000
  patience: 5
  score: rouge-L

task: TextSumTask